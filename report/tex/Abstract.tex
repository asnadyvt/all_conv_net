\begin{abstract} 
We review Striving for Simplicity: The All Convolutional Net by Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. Conventionally, convolutional neural nets (CNN) are built by alternating convolutional and max-pooling layers together with a few fully connected layers and a softmax layer at the end. However, state-of-the-art convolutional architectures have increasingly deviated the above model which begs the question of which components of a conventional convolutional net are responsible for achieving state-of-the-art performance. The authors demonstrate that the pooling function can be represented with the convolutional function and show that nets made out of only convolutional layers and a softmax layers can produce results comparable to, if not better than state-of-the-art performance on several object recognition datasets. They also introduce a new variant of the 'deconvolution approach' for visualizing features learned by CNNs that are applicable to a broader range of network structures. 

Here, we replicate the neural nets proposed in the paper and attempt to visualize the first three layers of the neural net consisting of only convolutional layers and a softmax layer with the guided backpropagation method.
\end{abstract} 